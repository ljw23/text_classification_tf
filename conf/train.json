{
  "task_info":{
    "label_type": "multi_label"
  },
  "rest":false,
  "input_length": 80,
  "num_classes": 1,
  "logits_type":"",
  "device": "cuda",
  "model_name": "textcnn",
  "checkpoint_dir": "./ckpt/",
  "model_dir": "trained_model_rcv1",
  "data": {
    "type":"json",
    "train_files": [
      "data/train.json"
    ],
    "validate_files": [
      "data/dev.json"
    ],
    "test_files": [
      "data/test.json"
    ]
  },
  "feature": {
    "feature_names": [
      "token"
    ],
    "min_token_count": 2,
    "min_char_count": 2,
    "token_ngram": 0,
    "min_token_ngram_count": 0,
    "min_keyword_count": 0,
    "min_topic_count": 2,
    "max_token_dict_size": 1000000,
    "max_char_dict_size": 150000,
    "max_token_ngram_dict_size": 10000000,
    "max_keyword_dict_size": 100,
    "max_topic_dict_size": 100,
    "max_token_len": 256,
    "max_char_len": 1024,
    "max_char_len_per_token": 4,
    "token_pretrained_file": "",
    "keyword_pretrained_file": ""
  },
  "train": {
    "batch_size": 64,
    "start_epoch": 1,
    "num_epochs": 5,
    "num_epochs_static_embedding": 0,
    "decay_steps": 1000,
    "decay_rate": 1.0,
    "clip_gradients": 100.0,
    "l2_lambda": 0.0,
    "loss_type": "SoftmaxCrossEntropy",
    "sampler": "fixed",
    "num_sampled": 5,
    "visible_device_list": "0",
    "hidden_layer_dropout": 0.5
  },
  "loss":{
    "type": "SoftmaxCrossEntropy",
    "focal_loss":{
      "gamma":2.0,
      "alpha":0.25,
      "epsilon":1e-9
    },
    "from_logits":false
  },
  "embedding": {
    "use_embedding":true,
    "vocab_size":21128,
    "hidden_size": 768,
    "embedding_size": null,
    "hidden_dropout": 0.1,
    "use_token_type": true,
    "use_position_embeddings": true,
    "token_type_vocab_size":2,
    "support_masking":true,
    "position_size":512,
    "pretrain_embeddings_file":null,
    "type": "embedding",
    "dimension": 64,
    "pretrain_initializer": "D:\\code\\text_classification_tf\\conf\\bert_embed.npy",
    "initializer": "uniform",
    "dropout": 0.0
  },
  "optimizer": {
    "optimizer_type": "Adam",
    "learning_rate": 0.008,
    "adadelta_decay_rate": 0.95,
    "adadelta_epsilon": 1e-08
  },
  "TextCNN": {

    "kernel_sizes": [
      2,
      3,
      4
    ],
    "filter_sizes": [64,64,64],
    "input_length": 80,
    "num_kernels": 100,
    "top_k_max_pooling": 1
  },
   "MLP": {
     "layer_num":3,
     "num_classes":2,
     "classify": false,
     "hiden_dimensions":[256,128]
  },
   "CNN": {
     "num_classes":1,
     "input_length": 6,
     "input_dim": 841,
     "classify": false,
     "kernel_size": 1
  },
  "RNN": {
    "hidden_dimension": 64,
    "rnn_type": "LSTM",
    "num_layers": 1,
    "use_bias": true,
    "activation": "relu",
    "doc_embedding_type": "Attention",
    "attention_dimension": 16,
    "num_classes": 1,
    "l2": 1e-3,
    "classify": false,
    "bidirectional": false
  },
  "TextBiRNN": {
    "hidden_dimension": 64,
    "rnn_type": "LSTM",
    "num_layers": 1,
    "use_bias": true,
    "activation": "relu",
    "doc_embedding_type": "Attention",
    "attention_dimension": 16,
    "num_classes": 1,
    "l2": 1e-3,
    "classify": false,
    "bidirectional": false
  },
  "TextDCNN": {
    "kernel_sizes": [[10, 7, 5], [6, 4, 3]],
    "filters": 256,
    "input_dim":10000,
    "embedding_dimension": 100,
    "input_length": 80,
    "num_kernels": 100,
    "num_classes": 1,
    "dropout":0.5,
    "top_k_max_pooling": 1
  },
  "TextRNN": {
    "input_dim":10000,
    "embedding_dimension": 100,
    "input_length": 80,
    "hidden_dimension": 64,
    "rnn_type": "GRU",
    "num_layers": 1,
    "use_bias": true,
    "activation": "relu",
    "doc_embedding_type": "Attention",
    "attention_dimension": 16,
    "num_classes": 1,
    "l2": 1e-3,
    "bidirectional": true
  },
  "TextSWEM": {
    "input_dim":10000,
    "embedding_dimension": 100,
    "input_length": 80,
    "num_classes": 1,
    "type": "concat"
  },
  "DRNN": {
    "hidden_dimension": 5,
    "window_size": 3,
    "rnn_type": "GRU",
    "bidirectional": true,
    "cell_hidden_dropout": 0.1
  },
  "eval": {
    "text_file": "data/rcv1_test.json",
    "threshold": 0.5,
    "dir": "eval_dir",
    "batch_size": 1024,
    "is_flat": true,
    "top_k": 100,
    "model_dir": "checkpoint_dir_rcv1/TextCNN_best"
  },
  "TextVDCNN": {
    "input_dim":10000,
    "embedding_dimension": 100,
    "input_length": 80,
    "vdcnn_depth": 9,
    "pool_type":"conv",
    "num_classes":1,
    "top_k_max_pooling": 3
  },
  "DPCNN": {
    "input_dim":10000,
    "embedding_dimension": 100,
    "input_length": 80,
    "num_classes":1,
    "l2": 1e-9,
    "filters":64,
    "spatial_dropout":0.2,
    "dropout":0.5,
    "repeat": 4,
    "kernel_size": 3,
    "pooling_stride": 2,
    "num_kernels": 16,
    "blocks": 2
  },
  "TextRCNN": {
    "kernel_sizes": [
        2,
        3,
        4
    ],
    "num_kernels": 100,
    "top_k_max_pooling": 1,
    "hidden_dimension":64,
    "rnn_type": "GRU",
    "num_layers": 1,
    "bidirectional": true
  },
  "Transformer": {
    "d_inner": 128,
    "d_k": 32,
    "d_v": 32,
    "n_head": 4,
    "n_layers": 1,
    "dropout": 0.1,
    "use_star": true
  },
  "AttentiveConvNet": {
    "attention_type": "bilinear",
    "margin_size": 3,
    "type": "advanced",
    "hidden_size": 64
  },
  "log": {
    "logger_file": "log_test_rcv1_hierar",
    "log_level": "warn"
  }
}
